%
\chapter{Fundamentals}\label{cha:Fundamentals}
%
%Eine wissenschaftliche Abschlussarbeit kann im Allgemeinen in die folgenden 4 Phasen gegliedert werden.
%
\section{Properties of Truck at Carola-Cup}\label{sec:Properties of Truck at Carolo-Cup}
%
The Carolo-Cup is an annual competition at the Technical University of Braunschweig which are attended by students. Every year the truck and some properties of the competition are changing. For example, in the competitions until 2017 there was no traffic sign, but starting in 2017 there are also some traffic signs, speed limit zones, blocked areas and crosswalks for pedestrian. Because of this, in the competitions until 2017, there was only one way to understand who had the right of way. If there is a stop line on the road in front of an intersection, it means the car has to wait until the intersection is free. In the competitions starting from 2017, the intersections are in different parts: They are 'Intersections with stop lines', 'Intersections with give-way lines', 'Intersections with priority to right', 'Enforced crossing direction - give-way condition', 'Enforced crossing direction - right of way condition'. Except 'Intersections with priority to right', they all have traffic signs stating who has priority. If there is a no traffic sign, it means the right side always has priority.\cite{Carolo_Cup}

\begin{figure}[H]
	\centering
	\hspace*{0cm}   
	\includegraphics[width=120mm,scale=1]{./Bilder/Intersections.png}
	\caption{Left: Markings for sharp turns at Carolo-Cup.
Right: Intersections with stop lines at Carolo-Cup\cite{Carolo_Cup}}
\end{figure}

%
\section{Inverse Perspective Mapping}\label{sec:Inverse Perspective Mapping}
%
Inverse Perspective Mapping(IPM) is an algorithm which is able to obtain accurate bird's-eye view images from the sequential of forward looking cameras. With the IPM algorithm, each image pixel is remapped, and a new array of pixels is created where the lines in perspective are transformed into straight lines and objects are distorted. IPM is one of the most used methods in lane detection. In lane detection, IPM ensures that the lanes are shown vertical and parallel to each other. On the other hand, because of the re-mapping of pixels, IPM is a computationally expensive method. Because of this reason, in some cases in this master's thesis, rather than remapping all pixels of the images, only the pixels relevant to the lane and accordingly, the fitted curve, were remapped. Thanks to this, in some cases, a lot of computing time was saved.

In order to use the IPM method, the intrinsic and extrinsic parameters of camera are necessary to process images for coordinate transformation and calibration.

\begin{itemize}

\item \textbf{Intrinsic Parameters :} Intrinsic parameters are camera-specific. It includes
information of the focal length ($f_x$, $f_y$) and optical centers ($c_x$, $c_y$). It is also called a camera matrix. Although the intrinsic parameters are camera-specific, once the camera is calibrated, the modified intrinsic parameters can be stored for future purposes. It is expressed as a 3x3 matrix:

 \begin{center}
  camera matrix =  $
 \begin{bmatrix} 
f_x & 0 & c_x \\
0 & f_y & c_y \\
0 & 0 & 1 \\
\end{bmatrix}
$  \end{center}

\item \textbf{Extrinsic Parameters :} Extrinsic parameters are dependent on the camera position. The parameters are H and $\theta$. H is the distance between the camera and ground. $\theta$ is the camera tilt angle. 
 
\end{itemize}
  
\begin{figure}[H]
\centering
  \includegraphics[width=0.8\textwidth]{./Bilder/Related_positions_of_the_camera.png}\label{Procedures_of_IPM}
  \caption{Related Positions of the Camera \cite{IPM}}
\end{figure}

 As seen at \ref{Procedures_of_IPM}, the camera on the car has field of view 2(FOV2) at the real position of the camera but in this case, the view is not a bird's-eye view, so if the same FOV is to be observed from a bird's-eye view, IPM will virtually change the position to Virtual Position 2 of the camera. In this case, although the camera is at its real position, it will appear as though it is at Virtual Position 2. For that, the image coordinates must also be changed. Below, the steps of IPM calculations from the paper of \cite{IPM} will be detailed.
 
In the formula, the original image coordinates will be defined as (x,y), the destination image coordinates will be defined as ($x^*$,$y^*$), the distance between the ground and the camera will be defined as H, the focal length of camera will be defined as f, and the tilt angle of camera will be defined as $\theta$.
 
\begin{center}
 $x^* = H \frac{x sin \theta + f cos \theta}{-y cos \theta + f sin \theta}$ ;
 $y^* = H \frac{y sin \theta + f cos \theta}{-y cos \theta + f sin \theta}$ 
\end{center}

In this equation, the transformed component values of $x^*$ and $y^*$ may be less than or equal to zero. Because of 
this reason, a constant d is defined as $
\begin{vmatrix}
H(sin \theta + cos \theta)/(f sin \theta - cos \theta) 
\end{vmatrix}
$  + 1. This means that the coordinate point in the original source image has been mapped into the point of the destination image coordinate system. Below there is the proposed equation :
 
 \begin{center}
 $x^* = H \frac{x sin \theta + f cos \theta}{-y cos \theta + f sin \theta}$ + d ,
 $y^* = H \frac{y sin \theta + f cos \theta}{-y cos \theta + f sin \theta}$ + d ,
 where d = 
 $\begin{vmatrix}
 \frac{H(sin \theta + f cos \theta)}{f sin \theta - cos \theta}
 \end{vmatrix}$ + 1
\end{center}

\begin{figure}[H]
 \centering
  \includegraphics[width=1\textwidth]{./Bilder/Procedures_of_IPM.png}\label{Procedures_of_IPM}
  \caption{Procedures of IPM}
\end{figure}


%
\section{Edge Detection}\label{sec:Edge Detection}
%

Edge detectors are essential parts of most computer vision systems. Edge detectors dramatically decrease the amount of data to be processed and extract the useful parts of images. They work by detecting discontinuities in brightness. In this project, the edge detector was used in order to detect the lanes and to exclude unnecessary information from images. There are different methods for edge detection, but they can be grouped into two categories. They are :

\begin{itemize}

\item \textbf{Gradient method : } This method searches for the maximum and minimum in the first derivative of the image and with that, the edges can be found. For this method, the first order derivative filter must be used. For example : Sobel-Operator.
 
\item \textbf{Laplacian method : } This method searches for the zero crossing in the second derivative of the image and with that, the edges can be found. For this method, the second order derivative filter must be used. For example : Laplacian Filter. 
  
\end{itemize}
 
According to \cite{Machine_Vision},here are three steps of the edge detection algorithm. They are :

\begin{itemize}

\item \textbf{Filtering : } For edge detection, it is required to use a suitable smoothing filter. The filters sharpen the edges and ignore the unnecessary information. It is often utilized to improve the functioning of an edge detector against noise. The more filtering is applied, however, the greater the loss of edge strength.
 
\item \textbf{Enhancement : } To be able to better detect edges, changes in the intensity in the area surrounding a point must be determined. Pixels in which a significant change in intensity occurs are emphasized by enhancement, which is usually applied by calculating the gradient magnitude.
  
\item \textbf{Detection : } Though many points in an image have a nonzero value for the gradient, not all of these points are actually edges. Because only points with strong edge content are desired, a method must be applied to determine which points are actual edge points. Thresholding is often utilized to do so.
 
\end{itemize}

Well known smoothing filters are :

\begin{itemize}

 \item Sobel-Operator
 \item Canny Edge Detector
 \item Laplacian-Filter
 \item Prewitt-Operator
 
 \end{itemize}
 
In this master's thesis, the Sobel Operator was utilized, so it will be described in more detail.

%
\subsection{Sobel Operator}\label{sec:Sobel Operator}

The Sobel Operator, sometimes called the Sobel filter is one of the most used edge detectors in image processing and computer vision. The Sobel Operator uses vertical and horizontal masks. These masks used are odd-numbered square matrices and they are generally 3x3 matrices. Approximations of the derivatives for the horizontal changes and for the vertical changes are calculated by the operator by using two 3x3 kernels and convolving them with the original image. If A is defined as the source, if $G_{x}$ is an image which contains the horizontal derivative approximations at each point, and if $G_{y}$ is an imagine which contains the vertical derivative approximations at each point, then the calculations are:


\[
  G_{x} = 
  \begin{bmatrix}
	+1 & 0 & -1 \\
	+2 & 0 & -2 \\
	+1 & 0 & -1 \\
   \end{bmatrix} * A  \quad
  G_{y} = 
  \begin{bmatrix}
	+1 & +2 & +1 \\
	0 & 0 & 0 \\
	+1 & -2 & -1 \\
  \end{bmatrix} * A
\]

where * here denotes the 2-dimensional signal processing convolution operation.

Since the Sobel kernels can be decomposed as the products of an averaging and a differentiation kernel, they compute the gradient with smoothing. For example, \textbf{$G_{x}$}  can be written as

$  \begin{bmatrix}
	+1 & 0 & -1 \\
	+2 & 0 & -2 \\
	+1 & 0 & -1 \\
   \end{bmatrix} =  \begin{bmatrix}
	1 \\
	2 \\
	1 \\
  \end{bmatrix} \begin{bmatrix}
	+1 & 0 & -1
  \end{bmatrix}
$

The x-coordinate is defined here as increasing in the 'right'-direction, and the y-coordinate is defined as increasing in the 'down'-direction. At each point in the image, the resulting gradient approximations can be combined to give the gradient magnitude, using:

G = $\sqrt{ G_{x}^{2} + G_{y}^{2} }$

Using this information, we can also calculate the gradient's direction:

$\theta = atan(\dfrac{G_{y}}{G_{x}})$

where, for example, $\theta$ is 0 for a vertical edge which is lighter on the right side.\cite{Sobel_Operator}






\begin{figure}[H]
  \centering
  \subfloat[Original Image]{\includegraphics[width=0.4\textwidth]{./Bilder/Sobel_Original.png}\label{fig:f1}}
  \hfill
  \subfloat[Sobel Operator applied Image]{\includegraphics[width=0.4\textwidth]{./Bilder/Sobel_Operator.png}\label{fig:f2}}
  \caption{Sobel Operator\cite{Sobel_Operator}}
\end{figure} 


%
\subsection{Canny Edge Detector}\label{sec:Canny Edge Detector}

Canny edge detector was developed in 1986 and called with the name of its developer John F. Canny. Canny edge detector is also so popular edge detector like Sobel operator. Canny edge detector is a multi-stage algorithm and it can be analyzed in 5 different stages.\cite{Canny_Edge_Detector2}

\begin{enumerate}
\item \textbf{Noise Reduction : } To get so stabile lane detection results, we have to reduce/remove all noise from frames. Lane detection without filtering out the noise can cause false detection. Gaussian filter is used for removing noise in the frames. Gaussian filter blurs images and removes detail and noise. The size of Gaussian filter kernel must be (2k+1)x(2k+1). It is important to choose the size of Gaussien filter because if the size of kernel is larger, detector's sensitivity to noise is lower but on the other hand, with the increase in size of the Gaussian filter kernel, the localization error in the edge detection will also increase slightly. \cite{Canny_Edge_Detector}



\item \textbf{Finding Intensity Gradient of the Image : } Essentially, the Canny algorithm locates edges in image where the grayscale intensity changes most starkly. In order to find these areas, the gradients of the image must be determined. In order to determine the gradients at each pixel in the smoothed image, the Sobel operator is applied. The Sobel operator has already been thoroughly discussed in section \ref{sec:Sobel Operator}.

\item \textbf{Non-maximum Suppression : } Non-maximum suppression is an edge thinning technique which is used as an intermediate step in many computer vision algorithms. The image is scanned along the image gradient direction, and pixels that are not part of the local maxima are set to zero. This way, all image information that is not part of the local maxima is effectively suppressed.

\item \textbf{Double Thresholding : } The edge pixels remaining after applying non-maximum suppression provide a more accurate depiction of real edges in an image. Despite this, there are still some remaining edge pixels resulting from noise and color variation. Therefore, it is necessary to filter out edge pixels with a weak gradient value while preserving edge pixels with a high gradient value. In order to do this, high and low threshold values must be selected. Edge pixels are marked as strong edge pixels when gradient values are higher than the high threshold value. They are marked as weak edge pixels when gradient values are lower than the high threshold value and higher than the low threshold value. They are suppressed when their values are lower than the low threshold value. The two threshold values are determined empirically and are dependent on the content of a given image.


\item \textbf{Hysteresis Thresholding : } Hysteresis Thresholding is the last part of Canny Edge Detector. Until this step, strong edge pixels are extracted from the true edges but there are also some weak edge pixels, some of them are extracted from true edges and some of them are extracted from some noise. So the weak edge pixels which are extracted from true edge, should be strong edge pixels and the weak edge pixels which are extracted from noises must be removed. If there is a weak edge pixel, 8 neighbour pixels of that weak edge pixel is checked and if at least, one pixel of these neighbour pixels is a strong edge pixel then, this weak edge pixels stay as edges in the end picture. 

\end{enumerate}


\begin{figure}[H]
  \centering
  \subfloat[Original Image]{\includegraphics[width=0.4\textwidth]{./Bilder/Sobel_Original.png}\label{fig:f1}}
  \hfill
  \subfloat[Canny Edge Detector applied Image]{\includegraphics[width=0.4\textwidth]{./Bilder/Canny_Edge_Detector.png}\label{fig:f2}}
  \caption{Canny Edge Detector\cite{Canny_Edge_Detector}}
\end{figure} 





%
\section{Hough-Transformation}\label{sec:Hough-Transformation}
%
\emph{\color{red}The Hough Transformation is a technique which can be used to isolate features of a particular shape within an image.}\emph{\color{blue} The Hough Transformation, which is universally used today was invented by Richard O. Duda and Peter E. Hart in 1972 but related patent was taken by Paul Hough in 1962.\cite{Hough_Transformation} In computer vision, simple edges like straight lines, curves and ellipses are needed to be often detected because of this reason, this technique used often in computer vision and image processing. Hough Transformation is used mostly after an edge detection algorithm. There are different types of Hough Transformation. In this master thesis, two types of Hough Transformation was used. They are :}

\begin{itemize}

\item \textbf{Standard Hough-Transformation : }\emph{\color{blue}This type of Hough-Transformation is used mostly for detecting straight lines. It will be explained in detail, how the Standard Hough-Transformation works then it will be more clear why it is more suitable for detecting straight lines.}

\item \textbf{Probabilistic Hough-Transformation : }\emph{\color{blue} This type of Hough-Transformation is suitable for both straight lines and curves so in this master thesis, the Probabilistic Hough-Transform was used for detecting lanes. It will be explained how the Probabilistic Hough-Transformation works.}

\end{itemize}
%
\subsection{Standard Hough-Transformation}\label{sec:Standard Hough - Transformation}
%
\emph{\color{blue}The Standard Hough-Transformation, which is also called linear Hough-Transformation, is used for detecting straight lines. There are so many different forms for describing a line segment analytically. One of the convenient equation for describing a line in an image(Cartesian) space is :}

  \begin{center}

$ \rho = x cos \theta + y sin \theta $

  \end{center}
  
 \emph{\color{red} In this equation, \textit{$ \rho $} is the length of a normal from the origin to the line and \textit{$ \theta $} is the orientation of \textit{r} with respect to X-axis.}
 
 
 \begin{figure}[H]
 \centering
  \includegraphics[width=1\textwidth]{./Bilder/Standard_Hough_Transformation.png}\label{Standart_Hough_Transformation}
  \caption{Standart Hough Transformation\cite{Standart_Hough_Transformation}}
\end{figure}
 
\emph{\color{blue}In the left side of Figure \ref{Standart_Hough_Transformation}, a line is shown in an image (Cartesian) space and in the right side of same Figure is shown of the transformed of the same line to the Hough space. A point in the image (Cartesian) space is transformed as a sinusoidal curve in Hough space. A line can be defined as a set of points so a line is transformed as a set of sinusoids intersecting at a point to Hough Space. In this case, to detect points in the Hough space means also to detect the lines in Cartesian space. After detecting points in the Hough Space, the points must be inverse transformed to get corresponding lines in the Cartesian space.}

\emph{\color{blue}In this master thesis, for detecting Hough lines, the function of \textit{cv2.HoughLines()} in OpenCV was used. The function is :}

  \begin{center}
  
$HoughLines(dst, lines, \rho, \theta, threshold, srn, stn )  $

  \end{center}

The parameters of functions will be described in detail.\ref{Standart_Hough_Transformation2}
 
\begin{itemize}

\item \textbf{dst : }Output of the edge detector. It should be a grayscale image (although in fact it is a binary one).
 
\item \textbf{lines : }A vector that will store the parameters ($ \rho $, $ \theta $) of the detected lines.

\item \textbf{$ \rho $ : }The resolution of the parameter $ \rho $ in pixels. In this master thesis, \textbf{1 pixel} was used.

\item \textbf{$ \theta $ : }The resolution of the parameter $ \theta $ in radians. In this master thesis, \textbf{1 degree}(CV$ \_ $PI/180) was used.

\item \textbf{threshold : }The minimum number of intersections to 'detect' a line.

\item \textbf{srn and stn : }These both parameters are for the multi-scale Hough transformation. srn is a divisor for the distance resolution $ \rho $ and stn is a divisor for the distance resolution $ \theta $. Default values of both parameters are zero.

\end{itemize}

%
\subsection{Probabilistic Hough-Transformation}\label{sec:Probabilistic Hough-Transformation}
%




%
\section{K-Nearest Neighbors Algorithm}\label{sec:K-Nearest Neighbors Algorithm}
%
K-Nearest Neighbor(KNN) is an non-parametric lazy learning algorithm. The non-parametric technique means that it doesn't make any assumptions on the underlaying data distribution. In the definition of KNN, the term 'lazy learning algorithm' is used. It means it doesn't use the data training points to do any generalization. In other words, there is no explicit training phase or it is very minimal.  It also means that the training phase is pretty fast. Most of the lazy algorithms - especially KNN - make decisions based on the entire training data set. On the other hand, KNN is one of the top 10 data mining algorithms\cite{k_nearest_neighbors}.

\begin{figure}[H]
 \centering
  \includegraphics[width=1\textwidth]{./Bilder/k-nearest-neighbors.png}\label{Procedures_of_IPM}
  \caption{K-Nearest-Neighbors Algorithm\cite{k_nearest_neighbors_wikipedia}}
\end{figure}

The K-Nearest Neighbors Algorithm has advantages and disadvantages. According to \cite{k_nearest_neighbors_adv_disadv},the main advantages of KNN are simplicity, effectiveness, intuitiveness and competitive classification performance in many domains. On the other hand, KNN can have poor run-time performance when the training set is large. It is very sensitive to irrelevant or redundant features because all features contribute to the similarity and thus to the classification. The computation cost is also quite high because we need to compute distance of each query instance to all training samples. 

%
\section{Curve Fitting}\label{sec:Curve Fitting}

\emph{\color{red}Curve fitting is used to find the 'best fit' line or curve for a series of data points. Curve fitting produces mostly mathematical equations that can be used to find points anywhere along
the curve.\cite{Curve_Fitting}} They are several different types of curve fitting. Some of them are: linear, exponential, polynomial, exponential, power, logarithmic, etc. In this master thesis, polynomial curve fitting was used. Polynomial curve fitting differs from order of the polynomial. Polynomial curve fittings are called different names depending on their orders. First order polynomial curve fittings are called linear regression, second order as quadratic regression, and third order as cubic regression.


\begin{figure}[H]
 \centering
  \includegraphics[width=1\textwidth]{./Bilder/Curve_Fitting_Polynomial.png}\label{Curve_Fitting_Polynomial}
  \caption{Types of Polynomial Curve Fitting\cite{Curve_Fitting_Polynomial}}
\end{figure}


\emph{\color{blue}In this master thesis, curve fitting is used for getting the best mathematical descriptions of lanes. Curve fitting uses as input the Hough points, which appear on the lanes and give as output a mathematical equation. First order polynomial curve fitting is more suitable for defining straight lines and second order polynomial curve fitting is more suitable for defining curves. There are straight and curve lanes so first order polynomial curve fitting wouldn't be enough for our project because of this reason, in this master thesis, second order polynimal curve fitting is used.}

\emph{\color{blue}There are so many different methods for curve fitting. One of the most famous method is the least squares method. In this master thesis also the least squares method is used. Next, it will be described, how to generate a polynomial curve fitting with using the least squares method.}

\emph{\color{blue}A data set can be mostly expressed the relationship between variable with an equation which is mostly representated with a $k^{th}$ order polynomial. The general description of $ k^{th} $ is :}

\begin{center}
y = $ a_{k}x^{k} + ... + a_{1}x + a_{0} + \epsilon $ 
\end{center}

\emph{\color{blue}The general polynomial regression model with the error $\epsilon$ provide typically an estimate rather than an implicit value of the dataset for any given value of x. A data set which has N data points, can be described with the maximum order of the polynomial which is k = N - 1 but mostly the lowest possible order of polynomial is choosed.}

\emph{\color{blue} The aim of the least squares' method is to minimise the variance between dataset values and estimated values from the polynomial equation.}

\emph{\color{blue} For determining the coefficients of the polynomial regression model ($ a_{k}, a_{k-1}, ..., a_{1} $) must be solved the following linear equations.}

 $
 \begin{bmatrix}
N & $$\sum_{i=1}^{N} x_{i}$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{k}$$ \\
$$\sum_{i=1}^{N} x_{i}$$ & $$\sum_{i=1}^{N} x_{i}^2$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{k+1}$$ \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
$$\sum_{i=1}^{N} x_{i}^{k}$$ & $$\sum_{i=1}^{N} x_{i}^{k+1}$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{2k}$$ \\

\end{bmatrix}  \begin{bmatrix}
	 a_{0}  \\
	 a_{1}  \\
	 \vdots  \\
	 a_{k}  \\
  \end{bmatrix} = 
  \begin{bmatrix}
	 $$\sum_{i=1}^{N} y_{i}$$  \\
	 $$\sum_{i=1}^{N} x_{i}y_{i}$$  \\
	 \vdots  \\
	 $$\sum_{i=1}^{N} x_{i}^{k}y_{i}$$  \\
  \end{bmatrix}
$ 

\emph{\color{blue}The equations, which in stardard form of Ma = b can be solved with so many different methods. In this master thesis, \textit{Cramer's Rule} was used for solving for the polynomial coefficients of curve fitting. With the help of the determinants of the square matrix M can be solved the linear system of equations for finding the coefficients. Each of the coefficients $a_{k}$ may be determined using the following equation :}

\begin{center}
$a_{k} = \dfrac{det(M_{i})}{det(M)}$
\end{center}

\emph{\color{blue}For finding coefficients of polynomial curve fitting, we have to use the equation shown above so the determinate of $ M_{i} $ must be divided by determinate of M. Above, the equation Ma = b were shown so the determinate of M matrix can be calculated but for the determinate of $ M_{i} $ matrix, the M matrix must be modified. For finding the $ M_{i} $ matrix, the $ i^{th} $ column must be replaced with the column vector b, which was used at the equation Ma = b. For example, if the $ M_{0} $ matrix wanted to be determined, the M matrix must be modified like at the following\cite{Curve_Fitting2} :}


\[
 M = \begin{bmatrix}
N & $$\sum_{i=1}^{N} x_{i}$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{k}$$ \\
$$\sum_{i=1}^{N} x_{i}$$ & $$\sum_{i=1}^{N} x_{i}^2$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{k+1}$$ \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
$$\sum_{i=1}^{N} x_{i}^{k}$$ & $$\sum_{i=1}^{N} x_{i}^{k+1}$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{2k}$$ \\

\end{bmatrix} \quad
 M_{0} = \begin{bmatrix}
$$\sum_{i=1}^{N} y_{i}$$ & $$\sum_{i=1}^{N} x_{i}$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{k}$$ \\
$$\sum_{i=1}^{N} x_{i}y_{i}$$ & $$\sum_{i=1}^{N} x_{i}^2$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{k+1}$$ \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
$$\sum_{i=1}^{N} x_{i}^{k}y_{i}$$ & $$\sum_{i=1}^{N} x_{i}^{k+1}$$ & $\dots$ & $$\sum_{i=1}^{N} x_{i}^{2k}$$ \\

\end{bmatrix}
\]

\emph{\color{blue}In this master thesis, $ 2^{nd} $ order polynomial equation is used so just the values of $ a_{0}, a_{1} and a_{2} $ must be calculated. For understanding curve fitting better, we are going to develop the $ 2^{nd} $ order polynomial curve fit for the given dataset.}

\begin{center}
  \begin{tabular}{ | c | c | c | c | c | c | c |}
    \hline
    x & -3  &  -2  &  -1  & -0.2  &  1  &  3 \\ \hline
    y & 0.9 &  0.8 &  0.4 &  0.2  & 0.1 &  0 \\
    \hline
  \end{tabular}
\end{center}

\[
 M = \begin{bmatrix}
6 & -2.2 & 24.04 \\
-2.2 & 24.04 & -8.008 \\
24.04 & -8.008 & 180.0016 \\

\end{bmatrix} \quad
 M_{0} = \begin{bmatrix}
2.4 & -2.2 & 24.04 \\
-4.64 & 24.04 & -8.008 \\
11.808 & -8.008 & 180.0016 \\

\end{bmatrix} 
\]

\[
 M_{1} = \begin{bmatrix}
6 & 2.4 & 24.04 \\
-2.2 & -4.64 & -8.008 \\
24.04 & 11.808 & 180.0016 \\

\end{bmatrix} \quad
 M_{2} = \begin{bmatrix}
6 & -2.2 & 2.4 \\
-2.2 & 24.04 & -4.64 \\
24.04 & -8.008 & 11.808 \\

\end{bmatrix}
\]

$ a_{0} = \dfrac{det(M_{0})}{det(M)}   \Longrightarrow  a_{0} = \dfrac{ 2671.1962}{11661.2736} = 0.2291$  \vfill 
$ a_{1} = \dfrac{det(M_{1})}{det(M)} \Longrightarrow  a_{1} = \dfrac{ -1898.4602}{11661.2736} = -0.1628$  \vfill 
$ a_{2} = \dfrac{det(M_{2})}{det(M)} \Longrightarrow  a_{2} = \dfrac{ 323.7632}{11661.2736} = 0.0278$

\emph{\color{blue}In this case, the fitted curve function is :} \vfill 
\begin{center}
y = 0.0278$x^{2} $ - 0.1628x +0.2291
\end{center}

\begin{figure}[H]
 \centering
  \includegraphics[width=1\textwidth]{./Bilder/Curve_Fitting.png}\label{Curve_Fitting}
  \caption{Curve Fitting\cite{Curve_Fitting_Plot}}
\end{figure}



\section{Rectangle Method}\label{sec:Rectangle Method}


%




